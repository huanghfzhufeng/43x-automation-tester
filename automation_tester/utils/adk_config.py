"""
Google ADK é…ç½®æ¨¡å—

æä¾› LLM å’Œ Agent çš„é»˜è®¤é…ç½®
"""

import logging

from google.adk.agents.callback_context import CallbackContext
from google.adk.models.lite_llm import LiteLlm
from google.adk.models.llm_request import LlmRequest
from google.adk.models.llm_response import LlmResponse

from automation_tester.config import LLMConfig
from automation_tester.utils.context_limiter import AgentContextLimiter

logger = logging.getLogger(__name__)

# åˆå§‹åŒ– AgentContextLimiter
AgentContextLimiter.init_context_limiter()

# ä¸º Entrepreneur Agent è®¾ç½®æ¶ˆæ¯é™åˆ¶ï¼ˆé»˜è®¤ 20 æ¡ï¼‰
AgentContextLimiter.set_limit("entrepreneur", 20)

logger.info("âœ… AgentContextLimiter å·²åˆå§‹åŒ–ï¼Œentrepreneur agent æ¶ˆæ¯é™åˆ¶: 20 æ¡")

# åˆ›å»ºé»˜è®¤ LLM å®ä¾‹
DEFAULT_LLM = LiteLlm(
    model=LLMConfig.model,
    base_url=LLMConfig.base_url,
    api_key=LLMConfig.api_key,
    num_retries=LLMConfig.num_retries,
    temperature=LLMConfig.temperature,
    max_tokens=LLMConfig.max_tokens,
)


def before_model_callback(
    callback_context: CallbackContext, llm_request: LlmRequest
) -> LlmResponse | None:
    """
    LLM è°ƒç”¨å‰çš„å›è°ƒå‡½æ•°
    
    æ ¸å¿ƒåŠŸèƒ½ï¼š
    1. è®¾ç½®å½“å‰ Agent åç§°ï¼ˆå¯ç”¨ AgentContextLimiterï¼‰
    2. è¿‡æ»¤å†å²æ¶ˆæ¯ï¼Œåªä¿ç•™çº¯æ–‡æœ¬å¯¹è¯ï¼Œç§»é™¤ function calls ç­‰æ— å…³äº‹ä»¶
    3. ğŸ”¥ RAG æ£€ç´¢ï¼šæ ¹æ®å½“å‰é—®é¢˜æ£€ç´¢ç›¸å…³ææ–™ç‰‡æ®µ
    4. AgentContextLimiter ä¼šè‡ªåŠ¨æˆªæ–­è¶…é•¿æ¶ˆæ¯ï¼ˆé€šè¿‡ monkey patchï¼‰

    Args:
        callback_context: å›è°ƒä¸Šä¸‹æ–‡
        llm_request: LLM è¯·æ±‚

    Returns:
        Optional[LlmResponse]: è‡ªå®šä¹‰çš„ LLM å“åº”ï¼Œè¿”å› None åˆ™ç»§ç»­æ­£å¸¸æµç¨‹
    """
    from google.adk.flows.llm_flows.contents import _get_contents
    from google.genai import types
    
    llm_logger = logging.getLogger("entrepreneur_agent.llm_debug")
    
    try:
        # ğŸ”¥ å¯ç”¨ AgentContextLimiterï¼šè®¾ç½®å½“å‰ Agent åç§°
        agent_name = callback_context.agent_name
        AgentContextLimiter.set_current_agent_name(agent_name)
        
        # è·å– invocation_context å’Œ session
        invocation_context = callback_context._invocation_context
        session = invocation_context.session
        
        original_event_count = len(session.events)
        
        # æ‰¾åˆ°ç¬¬ä¸€æ¡ "user" æ¶ˆæ¯çš„ä½ç½®
        cut_idx = None
        for i, e in enumerate(session.events):
            if getattr(e, "author", None) == "user":
                cut_idx = i
                break
        
        # ä»ç¬¬ä¸€æ¡ user æ¶ˆæ¯å¼€å§‹ä¿ç•™
        if cut_idx is not None:
            filtered_events = session.events[cut_idx:]
        else:
            filtered_events = session.events
        
        # è¿‡æ»¤æ‰ function calls å’Œ function responsesï¼Œåªä¿ç•™çº¯æ–‡æœ¬å¯¹è¯
        filtered_events = [
            e for e in filtered_events
            if (
                e.author in {"user", "entrepreneur"}  # åªä¿ç•™ç”¨æˆ·å’Œåˆ›ä¸šè€…çš„æ¶ˆæ¯
                and not (bool(e.get_function_calls()) or bool(e.get_function_responses()))  # ç§»é™¤å·¥å…·è°ƒç”¨
            )
        ]
        
        filtered_event_count = len(filtered_events)
        
        # é‡æ–°æ„å»º llm_request.contents
        llm_request.contents = _get_contents(
            invocation_context.branch, 
            filtered_events, 
            callback_context.agent_name
        )
        
        contents_count_before = len(llm_request.contents)
        
        # ğŸ“Š è®°å½•æˆªæ–­å‰çš„æ¶ˆæ¯æ•°é‡
        logger.info(
            f"[before_model_callback] Agent: {agent_name} | "
            f"åŸå§‹äº‹ä»¶: {original_event_count} â†’ è¿‡æ»¤å: {filtered_event_count} â†’ "
            f"Contents: {contents_count_before} æ¡"
        )
        
        # æ³¨æ„ï¼šAgentContextLimiter ä¼šåœ¨åç»­çš„ litellm è°ƒç”¨ä¸­è‡ªåŠ¨æˆªæ–­ llm_request.contents
        # è¿™é‡Œä¸éœ€è¦æ‰‹åŠ¨æˆªæ–­ï¼Œåªéœ€è¦è®°å½•æ—¥å¿—
        
        # è°ƒè¯•æ—¥å¿—
        if llm_logger.isEnabledFor(logging.DEBUG):
            llm_logger.debug("=" * 80)
            llm_logger.debug("ğŸ” LLM è¯·æ±‚å†…å®¹ï¼ˆå·²è¿‡æ»¤ï¼Œå¾… AgentContextLimiter æˆªæ–­ï¼‰:")
            llm_logger.debug(f"   åŸå§‹äº‹ä»¶æ•°: {original_event_count}")
            llm_logger.debug(f"   è¿‡æ»¤åäº‹ä»¶æ•°: {filtered_event_count}")
            llm_logger.debug(f"   Contents æ•°é‡: {contents_count_before}")
            llm_logger.debug(f"   Agent æ¶ˆæ¯é™åˆ¶: {AgentContextLimiter.get_limit()} æ¡")
            
            for i, content in enumerate(llm_request.contents):
                role = getattr(content, 'role', 'unknown')
                parts = getattr(content, 'parts', [])
                text = parts[0].text[:100] if parts and hasattr(parts[0], 'text') else 'N/A'
                llm_logger.debug(f"   Content {i+1} [{role}]: {text}...")
            
            llm_logger.debug("=" * 80)
        
        # ğŸ”¥ RAG æ£€ç´¢ï¼šæ ¹æ®å½“å‰é—®é¢˜æ£€ç´¢ç›¸å…³ææ–™
        try:
            # æå–å½“å‰ç”¨æˆ·é—®é¢˜ï¼ˆæœ€åä¸€æ¡ user æ¶ˆæ¯ï¼‰
            current_question = None
            if llm_request.contents:
                for content in reversed(llm_request.contents):
                    if getattr(content, 'role', '') == 'user':
                        parts = getattr(content, 'parts', [])
                        if parts and hasattr(parts[0], 'text'):
                            current_question = parts[0].text
                            break
            
            if current_question and agent_name == "entrepreneur":
                # å°è¯•ä» session.state è·å– RAG service
                rag_service = session.state.get("rag_service")
                
                if rag_service:
                    logger.info(f"ğŸ” RAG æ£€ç´¢: query='{current_question[:50]}...'")
                    
                    # æ£€ç´¢ç›¸å…³ææ–™ç‰‡æ®µ
                    results = rag_service.search(current_question, top_k=3)
                    
                    if results:
                        # æ ¼å¼åŒ–æ£€ç´¢ç»“æœ
                        relevant_materials = []
                        for i, result in enumerate(results):
                            relevant_materials.append(
                                f"[ç›¸å…³ææ–™ {i+1}]\n{result.chunk}"
                            )
                        
                        materials_text = "\n\n".join(relevant_materials)
                        
                        # æ³¨å…¥åˆ° llm_request.contents çš„å¼€å¤´ï¼ˆåœ¨ system message ä¹‹åï¼‰
                        rag_content = types.Content(
                            role="user",
                            parts=[types.Part(
                                text=f"## ç›¸å…³é¡¹ç›®ææ–™\n\n{materials_text}\n\n## æŠ•èµ„äººé—®é¢˜\n"
                            )]
                        )
                        
                        # æ’å…¥åˆ°ç¬¬ä¸€æ¡ user æ¶ˆæ¯ä¹‹å‰
                        llm_request.contents.insert(1, rag_content)
                        
                        logger.info(
                            f"âœ… RAG æ£€ç´¢å®Œæˆ: æ³¨å…¥ {len(results)} ä¸ªç›¸å…³ç‰‡æ®µ, "
                            f"æ€»é•¿åº¦ {len(materials_text)} å­—ç¬¦"
                        )
                else:
                    llm_logger.debug("âš ï¸ RAG service æœªåˆå§‹åŒ–ï¼Œè·³è¿‡æ£€ç´¢")
        
        except Exception as e:
            logger.warning(f"âš ï¸ RAG æ£€ç´¢å¤±è´¥: {e}", exc_info=True)
        
    except Exception as e:
        # å¦‚æœè¿‡æ»¤å¤±è´¥ï¼Œè®°å½•é”™è¯¯ä½†ä¸å½±å“ä¸»æµç¨‹
        logger.warning(f"âš ï¸ å†å²æ¶ˆæ¯è¿‡æ»¤å¤±è´¥: {e}", exc_info=True)
    
    return None


def after_model_callback(
    callback_context: CallbackContext, llm_response: LlmResponse
) -> LlmResponse | None:
    """
    LLM è°ƒç”¨åçš„å›è°ƒå‡½æ•°

    Args:
        callback_context: å›è°ƒä¸Šä¸‹æ–‡
        llm_response: LLM å“åº”

    Returns:
        Optional[LlmResponse]: ä¿®æ”¹åçš„ LLM å“åº”
    """
    return llm_response


def before_agent_callback(
    callback_context: CallbackContext,
) -> None:
    """
    Agent è°ƒç”¨å‰çš„å›è°ƒå‡½æ•°

    Args:
        callback_context: å›è°ƒä¸Šä¸‹æ–‡

    Returns:
        None: è¿”å› None åˆ™ç»§ç»­æ­£å¸¸æµç¨‹
    """
    return None


def after_agent_callback(callback_context: CallbackContext) -> None:
    """
    Agent è°ƒç”¨åçš„å›è°ƒå‡½æ•°

    Args:
        callback_context: å›è°ƒä¸Šä¸‹æ–‡

    Returns:
        None: è¿”å› None åˆ™ç»§ç»­æ­£å¸¸æµç¨‹
    """
    return None


# é»˜è®¤ LLM é…ç½®
DEFAULT_LLM_CONFIG = {
    "model": DEFAULT_LLM,
    "before_model_callback": before_model_callback,
    "after_model_callback": after_model_callback,
}

# é»˜è®¤ Tool é…ç½®
DEFAULT_TOOL_CONFIG = {
    "before_tool_callback": None,
    "after_tool_callback": None,
}

# é»˜è®¤ Agent é…ç½®
DEFAULT_AGENT_CONFIG = {
    **DEFAULT_LLM_CONFIG,
    **DEFAULT_TOOL_CONFIG,
    "before_agent_callback": before_agent_callback,
    "after_agent_callback": after_agent_callback,
}
