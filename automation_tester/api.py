"""
43X Entrepreneur Agent Service

FastAPI æœåŠ¡ï¼Œæä¾›åˆ›ä¸šè€… Agent çš„ HTTP API æ¥å£ã€‚
ç”¨äº Chrome æ’ä»¶è°ƒç”¨ï¼Œæ¨¡æ‹Ÿåˆ›ä¸šè€…ä¸æŠ•èµ„ Agent å¯¹è¯ã€‚
"""

import asyncio
import contextlib
import logging
import time
from collections import OrderedDict
from typing import Any

from fastapi import FastAPI, HTTPException, Request, status
from fastapi.exceptions import RequestValidationError
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import JSONResponse
from pydantic import BaseModel

from automation_tester.config import AppConfig, LLMConfig
from automation_tester.utils.logging_config import LogContext, get_logger, setup_logging

# åˆå§‹åŒ–æ—¥å¿—ç³»ç»Ÿ
setup_logging()
logger = get_logger("entrepreneur_agent.service")


# è¿‡æ»¤ uvicorn çš„è®¿é—®æ—¥å¿—ä¸­é’ˆå¯¹ /health çš„è®°å½•ï¼Œé¿å…æ—¥å¿—è¿‡äºå†—é•¿
class _HealthAccessFilter(logging.Filter):
    def filter(self, record: logging.LogRecord) -> bool:
        try:
            msg = record.getMessage()
        except Exception:
            msg = str(getattr(record, "msg", ""))
        # ä»…å½“ä¸æ˜¯ /health è¯·æ±‚æ—¶æ‰è®°å½•
        return "/health" not in msg


logging.getLogger("uvicorn.access").addFilter(_HealthAccessFilter())

# åˆ›å»º FastAPI åº”ç”¨
app = FastAPI(
    title="43X Entrepreneur Agent Service",
    description="æ¨¡æ‹Ÿåˆ›ä¸šè€… Agent çš„ HTTP API æœåŠ¡",
    version="1.0.0",
)

# é…ç½® CORS - å…è®¸æ‰€æœ‰æ¥æºï¼ˆåŒ…æ‹¬ Chrome æ’ä»¶ï¼‰
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],  # å…è®¸æ‰€æœ‰æ¥æºï¼ŒåŒ…æ‹¬ chrome-extension://
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# ============================================================================
# LRU ä¼šè¯ç¼“å­˜
# ============================================================================

# ç¼“å­˜é…ç½®
MAX_CACHE_SIZE = 10  # æœ€å¤šç¼“å­˜ 10 ä¸ªä¼šè¯
CACHE_TIMEOUT = 3600  # ç¼“å­˜è¶…æ—¶æ—¶é—´ï¼ˆç§’ï¼‰ï¼Œ1å°æ—¶
CLEANUP_INTERVAL = 300  # è‡ªåŠ¨æ¸…ç†é—´éš”ï¼ˆç§’ï¼‰ï¼Œ5åˆ†é’Ÿ

# LRU ç¼“å­˜ï¼šsession_id -> {"agent": Agent, "last_activity": timestamp, "created_at": timestamp}
session_cache: OrderedDict[str, dict[str, Any]] = OrderedDict()

# ç¼“å­˜ç»Ÿè®¡
cache_stats = {
    "hits": 0,
    "misses": 0,
    "evictions": 0,
}

# åå°ä»»åŠ¡æ§åˆ¶
_cleanup_task = None


def get_from_cache(session_id: str) -> Any | None:
    """
    ä»ç¼“å­˜è·å– Agent å®ä¾‹

    Args:
        session_id: ä¼šè¯ ID

    Returns:
        Agent å®ä¾‹ï¼Œå¦‚æœä¸å­˜åœ¨æˆ–å·²è¿‡æœŸåˆ™è¿”å› None
    """
    if session_id in session_cache:
        cache_entry = session_cache[session_id]

        # æ£€æŸ¥æ˜¯å¦è¿‡æœŸ
        if time.time() - cache_entry["last_activity"] > CACHE_TIMEOUT:
            logger.info(f"ğŸ• ç¼“å­˜è¿‡æœŸ: {session_id}")
            session_cache.pop(session_id)
            cache_stats["evictions"] += 1
            cache_stats["misses"] += 1
            return None

        # æ›´æ–°è®¿é—®æ—¶é—´å¹¶ç§»åˆ°æœ«å°¾ï¼ˆLRUï¼‰
        cache_entry["last_activity"] = time.time()
        session_cache.move_to_end(session_id)

        cache_stats["hits"] += 1
        logger.debug(f"âœ… ç¼“å­˜å‘½ä¸­: {session_id}")
        return cache_entry["agent"]

    cache_stats["misses"] += 1
    logger.debug(f"âŒ ç¼“å­˜æœªå‘½ä¸­: {session_id}")
    return None


def add_to_cache(session_id: str, agent: Any):
    """
    æ·»åŠ  Agent å®ä¾‹åˆ°ç¼“å­˜

    Args:
        session_id: ä¼šè¯ ID
        agent: Agent å®ä¾‹
    """
    # å¦‚æœç¼“å­˜å·²æ»¡ï¼Œç§»é™¤æœ€ä¹…æœªä½¿ç”¨çš„é¡¹
    if len(session_cache) >= MAX_CACHE_SIZE and session_id not in session_cache:
        oldest_session_id, oldest_entry = session_cache.popitem(last=False)
        logger.info(
            f"ğŸ—‘ï¸  ç¼“å­˜å·²æ»¡ï¼Œæ·˜æ±°æœ€ä¹…æœªä½¿ç”¨çš„ä¼šè¯: {oldest_session_id} "
            f"(é—²ç½® {time.time() - oldest_entry['last_activity']:.0f}ç§’)"
        )
        cache_stats["evictions"] += 1

    # æ·»åŠ æˆ–æ›´æ–°ç¼“å­˜
    current_time = time.time()
    if session_id in session_cache:
        session_cache[session_id]["agent"] = agent
        session_cache[session_id]["last_activity"] = current_time
        logger.debug(f"ğŸ”„ æ›´æ–°ç¼“å­˜: {session_id}")
    else:
        session_cache[session_id] = {
            "agent": agent,
            "last_activity": current_time,
            "created_at": current_time,
        }
        logger.info(
            f"â• æ·»åŠ åˆ°ç¼“å­˜: {session_id} (ç¼“å­˜å¤§å°: {len(session_cache)}/{MAX_CACHE_SIZE})"
        )

    # ç§»åˆ°æœ«å°¾ï¼ˆæœ€è¿‘ä½¿ç”¨ï¼‰
    session_cache.move_to_end(session_id)


def remove_from_cache(session_id: str):
    """
    ä»ç¼“å­˜ç§»é™¤ Agent å®ä¾‹

    Args:
        session_id: ä¼šè¯ ID
    """
    if session_id in session_cache:
        session_cache.pop(session_id)
        logger.info(f"ğŸ—‘ï¸  ä»ç¼“å­˜ç§»é™¤: {session_id}")


def get_cache_stats() -> dict[str, Any]:
    """
    è·å–ç¼“å­˜ç»Ÿè®¡ä¿¡æ¯

    Returns:
        dict: ç¼“å­˜ç»Ÿè®¡ä¿¡æ¯
    """
    total_requests = cache_stats["hits"] + cache_stats["misses"]
    hit_rate = cache_stats["hits"] / total_requests if total_requests > 0 else 0

    return {
        "size": len(session_cache),
        "max_size": MAX_CACHE_SIZE,
        "hits": cache_stats["hits"],
        "misses": cache_stats["misses"],
        "evictions": cache_stats["evictions"],
        "hit_rate": f"{hit_rate:.2%}",
        "sessions": list(session_cache.keys()),
    }


async def cleanup_expired_sessions_background():
    """
    åå°ä»»åŠ¡ï¼šå®šæœŸæ¸…ç†è¿‡æœŸçš„ä¼šè¯
    """
    logger.info(f"ğŸ§¹ å¯åŠ¨åå°æ¸…ç†ä»»åŠ¡ (é—´éš”: {CLEANUP_INTERVAL}ç§’)")

    while True:
        try:
            await asyncio.sleep(CLEANUP_INTERVAL)

            expired_sessions = []
            current_time = time.time()

            # æŸ¥æ‰¾å¹¶æ¸…ç†è¿‡æœŸçš„ä¼šè¯
            for session_id, cache_entry in list(session_cache.items()):
                idle_time = current_time - cache_entry["last_activity"]
                if idle_time > CACHE_TIMEOUT:
                    expired_sessions.append(session_id)
                    session_cache.pop(session_id)
                    cache_stats["evictions"] += 1
                    logger.info(f"ğŸ—‘ï¸  è‡ªåŠ¨æ¸…ç†è¿‡æœŸä¼šè¯: {session_id} (é—²ç½® {idle_time:.0f}ç§’)")

            if expired_sessions:
                logger.info(f"âœ… è‡ªåŠ¨æ¸…ç†å®Œæˆ: ç§»é™¤ {len(expired_sessions)} ä¸ªè¿‡æœŸä¼šè¯")
                logger.info(f"ğŸ“Š å½“å‰ç¼“å­˜: {len(session_cache)}/{MAX_CACHE_SIZE} ä¼šè¯")

        except Exception as e:
            logger.error(f"âŒ åå°æ¸…ç†ä»»åŠ¡å‡ºé”™: {e}", exc_info=True)


# å…¼å®¹æ€§ï¼šä¿ç•™ active_agents åˆ«å
active_agents = session_cache

# ============================================================================
# åº”ç”¨ç”Ÿå‘½å‘¨æœŸäº‹ä»¶
# ============================================================================


@app.on_event("startup")
async def startup_event():
    """åº”ç”¨å¯åŠ¨æ—¶çš„åˆå§‹åŒ–"""
    global _cleanup_task

    logger.info("ğŸš€ åº”ç”¨å¯åŠ¨ä¸­...")
    logger.info(f"ğŸ“Š ç¼“å­˜é…ç½®: æœ€å¤§ {MAX_CACHE_SIZE} ä¼šè¯, è¶…æ—¶ {CACHE_TIMEOUT}ç§’")

    # å¯åŠ¨åå°æ¸…ç†ä»»åŠ¡
    _cleanup_task = asyncio.create_task(cleanup_expired_sessions_background())
    logger.info("âœ… åå°æ¸…ç†ä»»åŠ¡å·²å¯åŠ¨")


@app.on_event("shutdown")
async def shutdown_event():
    """åº”ç”¨å…³é—­æ—¶çš„æ¸…ç†"""
    global _cleanup_task

    logger.info("ğŸ›‘ åº”ç”¨å…³é—­ä¸­...")

    # åœæ­¢åå°æ¸…ç†ä»»åŠ¡
    if _cleanup_task:
        _cleanup_task.cancel()
        with contextlib.suppress(asyncio.CancelledError):
            await _cleanup_task
        logger.info("âœ… åå°æ¸…ç†ä»»åŠ¡å·²åœæ­¢")

    # æ¸…ç†æ‰€æœ‰ç¼“å­˜çš„ä¼šè¯
    session_count = len(session_cache)
    session_cache.clear()
    logger.info(f"âœ… å·²æ¸…ç† {session_count} ä¸ªç¼“å­˜ä¼šè¯")


# ============================================================================
# å¼‚å¸¸å¤„ç†
# ============================================================================


@app.exception_handler(RequestValidationError)
async def validation_exception_handler(request: Request, exc: RequestValidationError):
    """å¤„ç†è¯·æ±‚éªŒè¯é”™è¯¯ï¼Œè¿”å›è¯¦ç»†ä¿¡æ¯"""
    body = await request.body()
    body_str = body.decode("utf-8", errors="replace")

    logger.error("=" * 60)
    logger.error("âŒ è¯·æ±‚éªŒè¯å¤±è´¥ (422)")
    logger.error(f"   URL: {request.url}")
    logger.error(f"   Method: {request.method}")
    logger.error(f"   é”™è¯¯è¯¦æƒ…: {exc.errors()}")
    logger.error(f"   è¯·æ±‚ä½“: {body_str}")
    logger.error("=" * 60)

    return JSONResponse(
        status_code=status.HTTP_422_UNPROCESSABLE_ENTITY,
        content={"detail": exc.errors(), "body": body_str},
    )


# ============================================================================
# æ•°æ®æ¨¡å‹
# ============================================================================


class StartTestRequest(BaseModel):
    """å¯åŠ¨æµ‹è¯•è¯·æ±‚"""

    scenario_config: dict[str, Any]
    files_content: dict[str, str] | None = None
    files_path: dict[str, str] | None = None  # æ–°å¢ï¼šæ–‡ä»¶è·¯å¾„æ˜ å°„


class StartTestResponse(BaseModel):
    """å¯åŠ¨æµ‹è¯•å“åº”"""

    session_id: str
    scenario_name: str
    company_name: str


class AnswerRequest(BaseModel):
    """è·å–å›ç­”è¯·æ±‚"""

    session_id: str
    question: str


class AnswerResponse(BaseModel):
    """è·å–å›ç­”å“åº”"""

    answer: str
    round_number: int
    elapsed_time: float


class StopTestRequest(BaseModel):
    """åœæ­¢æµ‹è¯•è¯·æ±‚"""

    session_id: str


# ============================================================================
# API ç«¯ç‚¹
# ============================================================================


@app.post("/api/test/start", response_model=StartTestResponse)
async def start_test(request: StartTestRequest):
    """
    å¯åŠ¨æµ‹è¯•ï¼Œåˆ›å»º Entrepreneur Agent å®ä¾‹

    å¦‚æœä¼šè¯å·²å­˜åœ¨äºç¼“å­˜ä¸­ï¼Œåˆ™å¤ç”¨ç°æœ‰ Runner å®ä¾‹ã€‚

    è¯·æ±‚æ ¼å¼:
    {
        "scenario_config": {
            "scenario_name": "å¿…å¡«",
            "company_name": "å¿…å¡«",
            ...å…¶ä»–å­—æ®µ
        },
        "files_content": {
            "filename.txt": "æ–‡ä»¶å†…å®¹å­—ç¬¦ä¸²",
            ...
        } æˆ– null
    }

    Args:
        request: åŒ…å«åœºæ™¯é…ç½®å’Œæ–‡ä»¶å†…å®¹çš„è¯·æ±‚

    Returns:
        StartTestResponse: åŒ…å« session_id å’Œåœºæ™¯ä¿¡æ¯
    """
    scenario_name = request.scenario_config.get("scenario_name", "unknown")
    company_name = request.scenario_config.get("company_name", "unknown")

    with LogContext(logger, f"å¯åŠ¨æµ‹è¯• - {scenario_name}"):
        try:
            logger.info("ğŸš€ æ”¶åˆ°å¯åŠ¨æµ‹è¯•è¯·æ±‚")
            logger.info(f"   åœºæ™¯åç§°: {scenario_name}")
            logger.info(f"   å…¬å¸åç§°: {company_name}")
            logger.info(f"   è¡Œä¸š: {request.scenario_config.get('industry', 'N/A')}")

            # è®°å½•ç¼“å­˜çŠ¶æ€
            cache_stats_info = get_cache_stats()
            logger.info(
                f"ğŸ“Š å½“å‰ç¼“å­˜çŠ¶æ€: {cache_stats_info['size']}/{cache_stats_info['max_size']} "
                f"(å‘½ä¸­ç‡: {cache_stats_info['hit_rate']})"
            )

            # å¤„ç†æ–‡ä»¶å†…å®¹
            bp_content_parts = []

            # æ–¹å¼1: ç›´æ¥ä¼ å…¥æ–‡ä»¶å†…å®¹ï¼ˆå…¼å®¹æ—§æ–¹å¼ï¼‰
            if request.files_content:
                logger.info(f"   ç›´æ¥ä¸Šä¼ æ–‡ä»¶æ•°: {len(request.files_content)}")

                import base64
                import os
                import tempfile

                from automation_tester.file import FileService, FileType
                from automation_tester.utils.file_utils import get_file_extension

                for filename, content in request.files_content.items():
                    logger.info(f"     - {filename}")

                    try:
                        ext = get_file_extension(filename)

                        # å®šä¹‰éœ€è¦ç‰¹æ®Šå¤„ç†çš„äºŒè¿›åˆ¶æ–‡ä»¶ç±»å‹
                        binary_extensions = ["pdf", "docx", "doc", "pptx", "ppt", "xlsx", "xls"]

                        # æ£€æµ‹æ˜¯å¦ä¸ºäºŒè¿›åˆ¶æ–‡ä»¶ï¼ˆbase64ç¼–ç ï¼‰
                        if ext in binary_extensions:
                            logger.info(f"       æ£€æµ‹åˆ°äºŒè¿›åˆ¶æ–‡ä»¶ç±»å‹: {ext}")
                            logger.info(f"       å†…å®¹é•¿åº¦: {len(content)} å­—ç¬¦")

                            # å°è¯•è§£ç base64
                            try:
                                # è§£ç base64
                                file_data = base64.b64decode(content)
                                logger.info(f"       Base64è§£ç æˆåŠŸ: {len(file_data)} å­—èŠ‚")

                                # åˆ›å»ºä¸´æ—¶æ–‡ä»¶
                                with tempfile.NamedTemporaryFile(
                                    delete=False, suffix=f".{ext}", mode="wb"
                                ) as tmp:
                                    tmp.write(file_data)
                                    tmp_path = tmp.name

                                logger.info(f"       ä¸´æ—¶æ–‡ä»¶: {tmp_path}")

                                # ä½¿ç”¨æ–‡ä»¶å¤„ç†æ¨¡å—è§£æ
                                file_type_map = {
                                    "pdf": FileType.PDF,
                                    "docx": FileType.WORD,
                                    "doc": FileType.WORD,
                                    "pptx": FileType.PPT,
                                    "ppt": FileType.PPT,
                                }

                                file_type = file_type_map.get(ext, FileType.TXT)
                                logger.info(f"       ä½¿ç”¨è§£æå™¨: {file_type.value}")

                                # è§£ææ–‡ä»¶
                                content_chunks = []
                                async for chunk in FileService.read_content(tmp_path, file_type):
                                    content_chunks.append(chunk)

                                parsed_content = "\n\n".join(content_chunks)
                                logger.info(f"       è§£ææˆåŠŸ: {len(parsed_content)} å­—ç¬¦")

                                # åˆ é™¤ä¸´æ—¶æ–‡ä»¶
                                try:
                                    os.unlink(tmp_path)
                                    logger.debug("       ä¸´æ—¶æ–‡ä»¶å·²åˆ é™¤")
                                except Exception as e:
                                    logger.warning(f"       åˆ é™¤ä¸´æ—¶æ–‡ä»¶å¤±è´¥: {e}")

                                # ä½¿ç”¨è§£æåçš„å†…å®¹
                                content = parsed_content

                            except Exception as decode_error:
                                logger.error(f"       Base64è§£ç æˆ–è§£æå¤±è´¥: {decode_error}")
                                # å¦‚æœè§£ç å¤±è´¥ï¼Œå°è¯•ä½œä¸ºæ™®é€šæ–‡æœ¬å¤„ç†
                                logger.info("       å›é€€åˆ°æ–‡æœ¬æ¨¡å¼")

                        # é™åˆ¶æ¯ä¸ªæ–‡ä»¶çš„é•¿åº¦ï¼Œé¿å…è¶…è¿‡ token é™åˆ¶
                        max_chars = 50000  # çº¦ 12,500 tokens
                        if len(content) > max_chars:
                            logger.warning(
                                f"   æ–‡ä»¶ [{filename}] è¿‡é•¿ ({len(content)} å­—ç¬¦)ï¼Œæˆªå–å‰ {max_chars} å­—ç¬¦"
                            )
                            content = content[:max_chars] + "\n\n[... å†…å®¹è¿‡é•¿ï¼Œå·²æˆªæ–­ ...]"

                        bp_content_parts.append(f"## æ–‡ä»¶: {filename}\n\n{content}")
                        logger.info(f"   æ–‡ä»¶å¤„ç†å®Œæˆ [{filename}]: {len(content)} å­—ç¬¦")

                    except Exception as e:
                        logger.error(f"   æ–‡ä»¶å¤„ç†å¤±è´¥ [{filename}]: {e}", exc_info=True)
                        bp_content_parts.append(f"## æ–‡ä»¶: {filename}\n\n[å¤„ç†å¤±è´¥: {e!s}]")

            # æ–¹å¼2: ä¼ å…¥æ–‡ä»¶è·¯å¾„ï¼Œä½¿ç”¨æ–‡ä»¶å¤„ç†æ¨¡å—è§£æï¼ˆæ–°æ–¹å¼ï¼‰
            if request.files_path:
                logger.info(f"   æ–‡ä»¶è·¯å¾„è§£ææ•°: {len(request.files_path)}")
                from automation_tester.file import FileService, FileType
                from automation_tester.utils.file_utils import get_file_extension

                for filename, filepath in request.files_path.items():
                    logger.info(f"     - {filename} -> {filepath}")

                    try:
                        # æ ¹æ®æ–‡ä»¶æ‰©å±•åç¡®å®šæ–‡ä»¶ç±»å‹
                        ext = get_file_extension(filename)
                        file_type_map = {
                            "pdf": FileType.PDF,
                            "docx": FileType.WORD,
                            "doc": FileType.WORD,
                            "pptx": FileType.PPT,
                            "ppt": FileType.PPT,
                            "md": FileType.MD,
                            "txt": FileType.TXT,
                            "jpg": FileType.IMAGE,
                            "jpeg": FileType.IMAGE,
                            "png": FileType.IMAGE,
                            "webp": FileType.IMAGE,
                        }

                        file_type = file_type_map.get(ext, FileType.TXT)
                        logger.info(f"       æ–‡ä»¶ç±»å‹: {file_type.value}")

                        # ä½¿ç”¨æ–‡ä»¶å¤„ç†æ¨¡å—è§£æ
                        content_chunks = []
                        async for chunk in FileService.read_content(filepath, file_type):
                            content_chunks.append(chunk)

                        content = "\n\n".join(content_chunks)

                        # é™åˆ¶é•¿åº¦
                        max_chars = 50000
                        if len(content) > max_chars:
                            logger.warning(
                                f"   æ–‡ä»¶ [{filename}] è§£æåè¿‡é•¿ ({len(content)} å­—ç¬¦)ï¼Œæˆªå–å‰ {max_chars} å­—ç¬¦"
                            )
                            content = content[:max_chars] + "\n\n[... å†…å®¹è¿‡é•¿ï¼Œå·²æˆªæ–­ ...]"

                        bp_content_parts.append(f"## æ–‡ä»¶: {filename}\n\n{content}")
                        logger.info(f"   æ–‡ä»¶è§£ææˆåŠŸ [{filename}]: {len(content)} å­—ç¬¦")

                    except Exception as e:
                        logger.error(f"   æ–‡ä»¶è§£æå¤±è´¥ [{filename}]: {e}")
                        bp_content_parts.append(f"## æ–‡ä»¶: {filename}\n\n[è§£æå¤±è´¥: {e!s}]")

            # åˆå¹¶æ‰€æœ‰æ–‡ä»¶å†…å®¹
            if bp_content_parts:
                request.scenario_config["bp_content"] = "\n\n".join(bp_content_parts)
            else:
                logger.info("   ä¸Šä¼ æ–‡ä»¶æ•°: 0")

            # åˆ›å»º Entrepreneur Agentï¼ˆä½¿ç”¨é‡æ„åçš„ Managerï¼‰
            from automation_tester.agents import EntrepreneurAgentManager

            agent = EntrepreneurAgentManager(request.scenario_config)

            # ğŸ”¥ æ·»åŠ åˆ° LRU ç¼“å­˜ï¼ˆå¦‚æœå·²å­˜åœ¨åˆ™æ›´æ–°ï¼‰
            add_to_cache(agent.session_id, agent)
            logger.debug("ğŸ§° Agent ä¼šè¯å·²é¢„åˆå§‹åŒ–ï¼Œå‡†å¤‡è¿›è¡Œå¤šè½®å¯¹è¯")

            logger.info("âœ… Agent åˆ›å»ºæˆåŠŸ")
            logger.info(f"   Session ID: {agent.session_id}")

            # è®°å½•è¯¦ç»†çš„ç¼“å­˜çŠ¶æ€
            cache_stats_info = get_cache_stats()
            logger.info("ğŸ“Š ç¼“å­˜çŠ¶æ€æ›´æ–°:")
            logger.info(f"   - ç¼“å­˜å¤§å°: {cache_stats_info['size']}/{cache_stats_info['max_size']}")
            logger.info(f"   - å‘½ä¸­ç‡: {cache_stats_info['hit_rate']}")
            logger.info(f"   - æ€»å‘½ä¸­: {cache_stats_info['hits']}")
            logger.info(f"   - æ€»æœªå‘½ä¸­: {cache_stats_info['misses']}")
            logger.info(f"   - æ€»æ·˜æ±°: {cache_stats_info['evictions']}")

            return StartTestResponse(
                session_id=agent.session_id, scenario_name=scenario_name, company_name=company_name
            )

        except Exception as e:
            logger.error(f"âŒ å¯åŠ¨æµ‹è¯•å¤±è´¥: {e}", exc_info=True)
            raise HTTPException(status_code=500, detail=str(e)) from e


@app.post("/api/test/answer", response_model=AnswerResponse)
async def get_answer(request: AnswerRequest):
    """
    è·å– Agent å¯¹é—®é¢˜çš„å›ç­”

    ä»ç¼“å­˜ä¸­è·å– Runner å®ä¾‹ï¼Œè‡ªåŠ¨å¤„ç†ç¼“å­˜è¿‡æœŸã€‚

    Args:
        request: åŒ…å« session_id å’Œé—®é¢˜çš„è¯·æ±‚

    Returns:
        AnswerResponse: åŒ…å«å›ç­”å’Œç»Ÿè®¡ä¿¡æ¯
    """
    with LogContext(logger, f"å¤„ç†é—®é¢˜ - {request.session_id[:16]}..."):
        try:
            logger.info("ğŸ’¬ æ”¶åˆ°é—®é¢˜è¯·æ±‚")
            logger.info(f"   Session ID: {request.session_id}")
            logger.info(f"   âš ï¸ é—®é¢˜å®Œæ•´å†…å®¹: [{request.question}]")  # æ‰“å°å®Œæ•´é—®é¢˜ï¼Œç”¨æ–¹æ‹¬å·åŒ…è£¹
            logger.info(f"   é—®é¢˜é•¿åº¦: {len(request.question)} å­—ç¬¦")
            logger.info(
                f"   é—®é¢˜æ˜¯å¦ä¸ºç©º: {not request.question or request.question.strip() == ''}"
            )

            # ğŸ”¥ ä»ç¼“å­˜è·å– Agentï¼ˆè‡ªåŠ¨å¤„ç†è¿‡æœŸï¼‰
            agent = get_from_cache(request.session_id)

            if agent is None:
                logger.error(f"âŒ Session not found or expired: {request.session_id}")
                logger.error(f"   å½“å‰æ´»è·ƒä¼šè¯: {list(session_cache.keys())}")

                # è®°å½•ç¼“å­˜çŠ¶æ€
                cache_stats_info = get_cache_stats()
                logger.error(
                    f"ğŸ“Š ç¼“å­˜çŠ¶æ€: {cache_stats_info['size']}/{cache_stats_info['max_size']} "
                    f"(å‘½ä¸­ç‡: {cache_stats_info['hit_rate']})"
                )

                raise HTTPException(status_code=404, detail="Session not found or expired")

            # ç”Ÿæˆå›ç­”
            answer = await agent.answer(request.question)
            stats = agent.get_stats()

            logger.info("âœ… å›ç­”ç”ŸæˆæˆåŠŸ")
            logger.info(f"   è½®æ¬¡: {stats['round_count']}")
            logger.info(f"   æ€»è€—æ—¶: {stats['elapsed_time']:.2f}s")
            logger.info(f"   å¹³å‡è€—æ—¶: {stats['avg_time_per_round']:.2f}s/è½®")

            # è®°å½•ç¼“å­˜çŠ¶æ€
            cache_stats_info = get_cache_stats()
            logger.debug(
                f"ğŸ“Š ç¼“å­˜çŠ¶æ€: {cache_stats_info['size']}/{cache_stats_info['max_size']} "
                f"(å‘½ä¸­ç‡: {cache_stats_info['hit_rate']})"
            )

            return AnswerResponse(
                answer=answer, round_number=stats["round_count"], elapsed_time=stats["elapsed_time"]
            )

        except HTTPException:
            raise
        except Exception as e:
            logger.error(f"âŒ è·å–å›ç­”å¤±è´¥: {e}", exc_info=True)
            raise HTTPException(status_code=500, detail=str(e)) from e


@app.post("/api/test/stop")
async def stop_test(request: StopTestRequest):
    """
    åœæ­¢æµ‹è¯•ï¼Œæ¸…ç† Agent å®ä¾‹

    Args:
        request: åŒ…å« session_id çš„è¯·æ±‚

    Returns:
        dict: çŠ¶æ€ä¿¡æ¯
    """
    with LogContext(logger, f"åœæ­¢æµ‹è¯• - {request.session_id[:16]}..."):
        try:
            logger.info("ğŸ›‘ æ”¶åˆ°åœæ­¢æµ‹è¯•è¯·æ±‚")
            logger.info(f"   Session ID: {request.session_id}")

            if request.session_id in session_cache:
                cache_entry = session_cache[request.session_id]
                agent = cache_entry["agent"]
                stats = agent.get_stats()

                logger.info("ğŸ“Š æµ‹è¯•ç»Ÿè®¡ä¿¡æ¯:")
                logger.info(f"   åœºæ™¯: {stats['scenario_name']}")
                logger.info(f"   å…¬å¸: {stats['company_name']}")
                logger.info(f"   æ€»è½®æ¬¡: {stats['round_count']}")
                logger.info(f"   æ€»è€—æ—¶: {stats['elapsed_time']:.2f}s")
                logger.info(f"   å¹³å‡è€—æ—¶: {stats['avg_time_per_round']:.2f}s/è½®")

                # è®¡ç®—ä¼šè¯å­˜æ´»æ—¶é—´
                session_lifetime = time.time() - cache_entry["created_at"]
                logger.info(f"   ä¼šè¯å­˜æ´»æ—¶é—´: {session_lifetime:.0f}ç§’")

                # ğŸ”¥ ä½¿ç”¨ç¼“å­˜ç®¡ç†å‡½æ•°ç§»é™¤
                remove_from_cache(request.session_id)

                logger.info("âœ… Session å·²æ¸…ç†")
                logger.info(f"   å‰©ä½™æ´»è·ƒä¼šè¯æ•°: {len(session_cache)}")
            else:
                logger.warning(f"âš ï¸  Session ä¸å­˜åœ¨: {request.session_id}")

            return {"status": "success", "message": "Test stopped"}

        except Exception as e:
            logger.error(f"âŒ åœæ­¢æµ‹è¯•å¤±è´¥: {e}", exc_info=True)
            raise HTTPException(status_code=500, detail=str(e)) from e


@app.get("/api/test/status/{session_id}")
async def get_status(session_id: str):
    """
    è·å–æµ‹è¯•çŠ¶æ€

    Args:
        session_id: ä¼šè¯ ID

    Returns:
        dict: çŠ¶æ€ä¿¡æ¯
    """
    try:
        logger.debug(f"ğŸ“Š æŸ¥è¯¢çŠ¶æ€: session_id={session_id}")

        # ğŸ”¥ ä½¿ç”¨ç¼“å­˜è·å–ï¼ˆè‡ªåŠ¨å¤„ç†è¿‡æœŸï¼‰
        agent = get_from_cache(session_id)

        if agent is None:
            logger.warning(f"âš ï¸  Session ä¸å­˜åœ¨æˆ–å·²è¿‡æœŸ: {session_id}")
            raise HTTPException(status_code=404, detail="Session not found or expired")

        stats = agent.get_stats()

        logger.debug(f"   è½®æ¬¡: {stats['round_count']}, è€—æ—¶: {stats['elapsed_time']:.2f}s")

        return {"status": "running", **stats}

    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"âŒ è·å–çŠ¶æ€å¤±è´¥: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail=str(e)) from e


@app.get("/api/cache/stats")
async def get_cache_statistics():
    """
    è·å–ç¼“å­˜ç»Ÿè®¡ä¿¡æ¯

    Returns:
        dict: è¯¦ç»†çš„ç¼“å­˜ç»Ÿè®¡ä¿¡æ¯
    """
    try:
        stats = get_cache_stats()

        # æ·»åŠ æ¯ä¸ªä¼šè¯çš„è¯¦ç»†ä¿¡æ¯
        session_details = []
        for session_id, cache_entry in session_cache.items():
            agent = cache_entry["agent"]
            agent_stats = agent.get_stats()

            idle_time = time.time() - cache_entry["last_activity"]
            lifetime = time.time() - cache_entry["created_at"]

            session_details.append(
                {
                    "session_id": session_id,
                    "scenario_name": agent_stats["scenario_name"],
                    "company_name": agent_stats["company_name"],
                    "round_count": agent_stats["round_count"],
                    "idle_time_seconds": round(idle_time, 2),
                    "lifetime_seconds": round(lifetime, 2),
                    "created_at": cache_entry["created_at"],
                    "last_activity": cache_entry["last_activity"],
                }
            )

        logger.info(f"ğŸ“Š ç¼“å­˜ç»Ÿè®¡æŸ¥è¯¢: {stats['size']}/{stats['max_size']} ä¼šè¯")

        return {
            **stats,
            "timeout_seconds": CACHE_TIMEOUT,
            "session_details": session_details,
        }

    except Exception as e:
        logger.error(f"âŒ è·å–ç¼“å­˜ç»Ÿè®¡å¤±è´¥: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail=str(e)) from e


@app.post("/api/cache/cleanup")
async def cleanup_expired_sessions():
    """
    æ‰‹åŠ¨æ¸…ç†è¿‡æœŸçš„ä¼šè¯

    Returns:
        dict: æ¸…ç†ç»“æœ
    """
    try:
        logger.info("ğŸ§¹ å¼€å§‹æ‰‹åŠ¨æ¸…ç†è¿‡æœŸä¼šè¯")

        expired_sessions = []
        current_time = time.time()

        # æŸ¥æ‰¾è¿‡æœŸçš„ä¼šè¯
        for session_id, cache_entry in list(session_cache.items()):
            idle_time = current_time - cache_entry["last_activity"]
            if idle_time > CACHE_TIMEOUT:
                expired_sessions.append(session_id)
                session_cache.pop(session_id)
                cache_stats["evictions"] += 1
                logger.info(f"ğŸ—‘ï¸  æ¸…ç†è¿‡æœŸä¼šè¯: {session_id} (é—²ç½® {idle_time:.0f}ç§’)")

        logger.info(f"âœ… æ¸…ç†å®Œæˆ: ç§»é™¤ {len(expired_sessions)} ä¸ªè¿‡æœŸä¼šè¯")

        return {
            "status": "success",
            "cleaned_count": len(expired_sessions),
            "cleaned_sessions": expired_sessions,
            "remaining_sessions": len(session_cache),
        }

    except Exception as e:
        logger.error(f"âŒ æ¸…ç†è¿‡æœŸä¼šè¯å¤±è´¥: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail=str(e)) from e


@app.post("/api/extract/info")
async def extract_info_from_files(request: Request):
    """
    ä»ä¸Šä¼ çš„æ–‡ä»¶ä¸­æå–é¡¹ç›®ä¿¡æ¯
    
    ä½¿ç”¨ LLM åˆ†ææ–‡ä»¶å†…å®¹ï¼Œæå–ç»“æ„åŒ–çš„é¡¹ç›®ä¿¡æ¯
    
    è¯·æ±‚æ ¼å¼:
    {
        "files_content": {
            "filename.pdf": "base64_content" or "text_content",
            ...
        }
    }
    
    Returns:
        dict: æå–çš„ç»“æ„åŒ–ä¿¡æ¯
    """
    # åœ¨å‡½æ•°å¼€å¤´å¯¼å…¥æ‰€æœ‰éœ€è¦çš„æ¨¡å—
    import base64
    import json
    import os
    import re
    import tempfile

    from automation_tester.file import FileService, FileType
    from automation_tester.utils.file_utils import get_file_extension
    from openai import OpenAI
    
    with LogContext(logger, "AIæå–ä¿¡æ¯"):
        try:
            body = await request.json()
            files_content = body.get("files_content", {})
            
            if not files_content:
                raise HTTPException(status_code=400, detail="æœªæä¾›æ–‡ä»¶å†…å®¹")
            
            logger.info(f"ğŸ“„ æ”¶åˆ° {len(files_content)} ä¸ªæ–‡ä»¶ï¼Œå¼€å§‹AIæå–")
            
            # å¤„ç†æ–‡ä»¶å†…å®¹
            all_text = []
            
            for filename, content in files_content.items():
                try:
                    ext = get_file_extension(filename)
                    logger.info(f"   å¤„ç†æ–‡ä»¶: {filename} ({ext})")
                    
                    # äºŒè¿›åˆ¶æ–‡ä»¶ç±»å‹
                    binary_extensions = ["pdf", "docx", "doc", "pptx", "ppt"]
                    
                    if ext in binary_extensions:
                        # è§£ç base64
                        file_data = base64.b64decode(content)
                        
                        # åˆ›å»ºä¸´æ—¶æ–‡ä»¶
                        with tempfile.NamedTemporaryFile(delete=False, suffix=f".{ext}", mode="wb") as tmp:
                            tmp.write(file_data)
                            tmp_path = tmp.name
                        
                        try:
                            # è§£ææ–‡ä»¶
                            file_type_map = {
                                "pdf": FileType.PDF,
                                "docx": FileType.WORD,
                                "doc": FileType.WORD,
                                "pptx": FileType.PPT,
                                "ppt": FileType.PPT,
                            }
                            
                            file_type = file_type_map.get(ext, FileType.TXT)
                            
                            content_chunks = []
                            async for chunk in FileService.read_content(tmp_path, file_type):
                                content_chunks.append(chunk)
                            
                            parsed_content = "\n\n".join(content_chunks)
                            all_text.append(f"## æ–‡ä»¶: {filename}\n\n{parsed_content}")
                            
                        finally:
                            # åˆ é™¤ä¸´æ—¶æ–‡ä»¶
                            try:
                                os.unlink(tmp_path)
                            except Exception:
                                pass
                    else:
                        # æ–‡æœ¬æ–‡ä»¶ç›´æ¥ä½¿ç”¨
                        all_text.append(f"## æ–‡ä»¶: {filename}\n\n{content}")
                    
                    logger.info(f"   âœ… æ–‡ä»¶å¤„ç†æˆåŠŸ: {filename}")
                    
                except Exception as e:
                    logger.error(f"   âŒ æ–‡ä»¶å¤„ç†å¤±è´¥: {filename} - {e}")
                    continue
            
            if not all_text:
                raise HTTPException(status_code=400, detail="æ— æ³•è§£æä»»ä½•æ–‡ä»¶å†…å®¹")
            
            combined_text = "\n\n---\n\n".join(all_text)
            
            # é™åˆ¶æ–‡æœ¬é•¿åº¦
            max_chars = 20000
            if len(combined_text) > max_chars:
                combined_text = combined_text[:max_chars] + "\n\n[... å†…å®¹è¿‡é•¿ï¼Œå·²æˆªæ–­ ...]"
            
            logger.info(f"ğŸ“ åˆå¹¶æ–‡æœ¬é•¿åº¦: {len(combined_text)} å­—ç¬¦")
            
            # ä½¿ç”¨ LLM æå–ä¿¡æ¯
            client = OpenAI(
                api_key=LLMConfig.api_key,
                base_url=LLMConfig.base_url,
            )
            
            extraction_prompt = f"""è¯·ä»ä»¥ä¸‹å•†ä¸šè®¡åˆ’ä¹¦æˆ–é¡¹ç›®èµ„æ–™ä¸­æå–å…³é”®ä¿¡æ¯ï¼Œä»¥JSONæ ¼å¼è¿”å›ã€‚

è¦æå–çš„å­—æ®µï¼š
- company_name: å…¬å¸åç§°ï¼ˆå­—ç¬¦ä¸²ï¼‰
- industry: è¡Œä¸šç±»å‹ï¼ˆå­—ç¬¦ä¸²ï¼Œå¦‚"AI SaaS"ã€"ä¼ä¸šæœåŠ¡"ç­‰ï¼‰
- product: äº§å“æè¿°ï¼ˆå­—ç¬¦ä¸²ï¼Œç®€è¦æè¿°ï¼‰
- revenue: è¥æ”¶æƒ…å†µï¼ˆå­—ç¬¦ä¸²ï¼Œå¦‚"ARR 500ä¸‡"ï¼‰
- team: å›¢é˜Ÿè§„æ¨¡ï¼ˆå­—ç¬¦ä¸²ï¼Œå¦‚"15äºº"ï¼‰
- funding_need: èèµ„éœ€æ±‚ï¼ˆå­—ç¬¦ä¸²ï¼Œå¦‚"Aè½® 2000ä¸‡"ï¼‰
- customers: å®¢æˆ·æ¡ˆä¾‹ï¼ˆæ•°ç»„ï¼Œå¦‚["é˜¿é‡Œå·´å·´", "è…¾è®¯"]ï¼‰
- technology: æ ¸å¿ƒæŠ€æœ¯ï¼ˆå­—ç¬¦ä¸²ï¼Œç®€è¦æè¿°ï¼‰

æ³¨æ„ï¼š
1. åªè¿”å›JSONæ ¼å¼ï¼Œä¸è¦å…¶ä»–è¯´æ˜æ–‡å­—
2. å¦‚æœæŸä¸ªå­—æ®µæ‰¾ä¸åˆ°ä¿¡æ¯ï¼Œä¸è¦åŒ…å«è¯¥å­—æ®µ
3. ç¡®ä¿JSONæ ¼å¼æ­£ç¡®

æ–‡æ¡£å†…å®¹ï¼š

{combined_text}

è¯·è¿”å›JSONï¼š"""
            
            logger.info("ğŸ¤– è°ƒç”¨ LLM æå–ä¿¡æ¯...")
            logger.info(f"   ä½¿ç”¨æ¨¡å‹: {LLMConfig.model}")
            
            response = client.chat.completions.create(
                model=LLMConfig.model,
                messages=[
                    {"role": "system", "content": "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„å•†ä¸šè®¡åˆ’ä¹¦åˆ†æåŠ©æ‰‹ï¼Œæ“…é•¿ä»æ–‡æ¡£ä¸­æå–ç»“æ„åŒ–ä¿¡æ¯ã€‚"},
                    {"role": "user", "content": extraction_prompt}
                ],
                temperature=0.3,
                max_tokens=1000,
            )
            
            result_text = response.choices[0].message.content.strip()
            logger.info(f"ğŸ“¤ LLM è¿”å›: {result_text[:200]}...")
            
            # è§£æJSONï¼ˆå°è¯•æå–JSONï¼Œå¯èƒ½åŒ…å«markdownä»£ç å—ï¼‰
            json_match = re.search(r'```(?:json)?\s*(\{.*?\})\s*```', result_text, re.DOTALL)
            if json_match:
                result_text = json_match.group(1)
            
            extracted_info = json.loads(result_text)
            
            logger.info(f"âœ… ä¿¡æ¯æå–æˆåŠŸ: {list(extracted_info.keys())}")
            
            return {
                "success": True,
                "extracted_info": extracted_info,
                "files_processed": len(files_content)
            }
            
        except HTTPException:
            raise
        except json.JSONDecodeError as e:
            logger.error(f"âŒ JSONè§£æå¤±è´¥: {e}")
            logger.error(f"   åŸå§‹æ–‡æœ¬: {result_text}")
            raise HTTPException(status_code=500, detail=f"AIè¿”å›çš„æ ¼å¼æ— æ³•è§£æ: {str(e)}")
        except Exception as e:
            logger.error(f"âŒ ä¿¡æ¯æå–å¤±è´¥: {e}", exc_info=True)
            raise HTTPException(status_code=500, detail=str(e))


@app.get("/health")
async def health_check():
    """å¥åº·æ£€æŸ¥"""
    logger.debug(f"ğŸ’š å¥åº·æ£€æŸ¥: æ´»è·ƒä¼šè¯æ•°={len(session_cache)}")
    return {"status": "ok", "active_sessions": len(session_cache)}


# ============================================================================
# ä¸»å‡½æ•°
# ============================================================================

if __name__ == "__main__":
    import uvicorn

    # éªŒè¯é…ç½®
    if not LLMConfig.api_key:
        logger.error("âŒ é…ç½®é”™è¯¯: LLM_API_KEY æœªè®¾ç½®")
        exit(1)

    logger.info("=" * 80)
    logger.info("ğŸš€ å¯åŠ¨ Entrepreneur Agent Service")
    logger.info(f"   ç›‘å¬åœ°å€: 0.0.0.0:{AppConfig.agent_service_port}")
    logger.info(f"   ç¯å¢ƒ: {AppConfig.env}")
    logger.info(f"   æ—¥å¿—çº§åˆ«: {AppConfig.log_level}")
    logger.info(f"   LLM æ¨¡å‹: {LLMConfig.model}")
    logger.info("=" * 80)

    uvicorn.run(app, host="0.0.0.0", port=AppConfig.agent_service_port, log_level="info")
